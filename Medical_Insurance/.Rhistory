?apply()
apply(algae, 1, function(x) sum(is.na(x)))
?data()
?manyNAs()
manyNAs(algae, 0.2)
manyNAs(algae, 0.2)
?manyNAs
nrow(algae[complete.cases(algae),])
manyNAs(algae,0.2)
algae[48,]
hist(algae$mxPH)
?hist()
hist(algae$mxPH, probability=T)
algae[48,"mxPH"] = mean(algae$mxPH, na.rm = T)
algae.header()
header(algae)
?header
?header()
head(algae)
hist(algae$chla)
summary(algae$chla)
class(algae$chla)
class(algae$Chla)
hist(algae$Chla)
summary(algae$Chla)
algae[is.na(algae$Chla), "Chla"] <- median(algae$Chla, na.rm = T)
nrow(algae[complete.cases(algae),])
?centralimputation()
?centralImputation()
cor(algae[, 4:18], use = "complete.obs")
?symnum()
symnum(cor(algae[,4:18],use="complete.obs"))
?lm()
algae = algae_original
algae <- algae[-manyNAs(algae), ]
lm(PO4 ~ oPO4, data = algae)
algae[28, "PO4"] <- 42.897 + 1.293 * algae[28, "oPO4"]
fillPO4 <- function(oP) {
if (is.na(oP))
return (NA)
else return(42.897 + 1.293*oP)
}
algae[is.na(algae$PO4), "PO4"] <- sapply(algae[is.na(algae$PO4),"oPO4"], fillPO4)
histogram(~mxPH | season, data = algae)
algae = algae_original
algae = algae[-manyNAs(algae),]
clean.algae <- knnImputation(algae, k = 10)
lm.a1 = lm(a1 ~ .,data=clean.algae[,1:12])
summary(lm.a1)
lm.a1
algae.head
head(algae)
str(lm.a1)
summary(lm.a1)
plot(lm.a1)
anova(lm.a1)
lm2.a1 <- update(lm.a1, . ~ . - season)
summary(lm2.a1)
anova(lm.a1,lm2.a1)
final.lm <- step(lm.a1)
summary(final.lm)
library(rpart)
?data()
data(algae)
algae <- algae[-manyNAs(algae), ]
nrow(algae)
rt.a1 <- rpart(a1 ~ ., data = algae[, 1:12])
rt.a1
prettyTree(rt.a1)
printcp(rt.a1)
printcp(rt.a1)
install.packages("caret")
open(kernlab)
library(kernlab)
?read.table()
pwd
getwd()
setwd("/Users/jananee009/Zananee/Projects/AutoMPG")
autoData.original = read.table('auto-mpg.data',header=F,dec='.',col.names=c('mpg','cylinders','displacement','horsepower','weight','acceleration','model_year','origin','carname'))
head(autoData.original)
autoData = autoData.original
autoData[,2:8]
autoData[1,]
autoData.TrainingSet = autoData[1:300,]
autoData.TestSet = autoData[301:398,]
lm.mpg = lm(mpg ~ .,data=autoData.TrainingSet[,2:8])
lm.mpg = lm(mpg ~ .,data=autoData.TrainingSet[,2:8])
autoData.TrainingSet[,2:8]
clean.algae[1,1:12]
lm.mpg = lm(mpg ~ .,data=autoData.TrainingSet[,1:8])
summary(lm.mpg)
summary(autoData.original)
identify(autoData.original$horsepower)
class(autoData.original)
identify(autoData.original)
identify(autoData.original$mpg)
mode(autoData.original$mpg)
mode(autoData.original$cylinders)
mode(autoData.original$displacement)
mode(autoData.original$horsepower)
class(autoData.original$displacement)
autoData$horsepower = as.numeric(autoData$horsepower)
summary(autoData)
autoData.TrainingSet = autoData[1:300,]
autoData.TestSet = autoData[301:398,]
lm.mpg = lm(mpg ~.,data=autoData.TrainingSet[,1:8])
summary(lm.mpg)
lm.mpg.predictions = predict(lm.mpg,autoData.TestSet,type="response")
summary(lm.mpg.predictions)
lm.mpg.predictions[1]
dim(lm.mpg.predictions)
class(lm.mpg.predictions)
nrow(lm.mpg.predictions)
mode(lm.mpg.predictions)
lm.mpg.predictions[1,2]
length(lm.mpg.predictions)
ncol(lm.mpg.predictions)
lm.mpg.predictions[1:98]
mae.lm.mpg = mean(abs(lm.mpg.predictions-autoData.TestSet[,1]))
mae.lm.mpg
mse.lm.mpg = mean((lm.mpg.predictions-autoData.TestSet[,1])^2)
mse.lm.mpg
print mse.lm.mpg
print(mse.lm.mpg)
sqrt(mse.lm.mpg)
install.packages("gmodels")
library(gmodels)
version
?read.csv()
wbcd = read.csv("wisc_bc_data.csv",header=TRUE,sep=",",stringsAsFactors=False)
getwd()
setwd("/Users/jananee009/Zananee/Projects/Breast_Cancer_Diagnosis")
wbcd = read.csv("wisc_bc_data.csv",header=TRUE,sep=",",stringsAsFactors=False)
wbcd = read.csv("wisc_bc_data.csv",header=TRUE,sep=",",stringsAsFactors=FALSE)
str(wbcd)
wbcd_original = wbcd
wbcd =  wbcd_original[-1]
head(wbcd)
table(wbcd$diagnosis)
wbcd$diagnosis = factor(wbcd$diagnosis, levels=c("B","M"),labels = c("Benign","Malignant"))
table(wbcd$diagnosis)
?prop.table()
m = matrix(1:4,2)
m
prop.table(m,1)
prop.table(table(wbcd$diagnosis)*100,digits=1)
round(prop.table(table(wbcd$diagnosis)*100,digits=1))
357+212
357/569
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
summary(wbcd)
normalize = function(x) {}
normalize = function(x) {
return ((x-min(x)) / (max(x) - min(x)))
}
normalize(c(1,2,3,4,5))
wbcd_n = as.data.frame(lapply(wbcd[2:31],normalize))
summary(wbcd_n)
nrow(wbcd_n)
ncol(wbcd_n)
head(wbcd_n)
wbcd_train = wbcd_n[1:469,]
wbcd_test = wbcd_n[470:569,]
wbcd_train_labels = wbcd[1:469,1]
wbcd_test_labels = wbcd[470:569,1]
library(class)
wbcd_test_pred = knn(train=wbcd_train, test=wbcd_test,cl=wbcd_train_labels,k=21)
library(gmodels)
?CrossTable()
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,prop.chisq=FALSE)
table(wbcd_test_pred)
table(wbcd_test_labels)
wbcd_z = as.data.frame(scale(wbcd[-1]))
summary(wbcd_z)
wbcd_train <- wbcd_z[1:469, ]
wbcd_test <- wbcd_z[470:569, ]
wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,cl = wbcd_train_labels, k=21)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,prop.chisq=FALSE)
getwd()
setwd("/Users/jananee009/Zananee/Projects/SpamDetection")
getwd()
sms_raw = read.csv("sms_spam.csv",stringAsFactors=FALSE)
sms_raw = read.csv("sms_spam.csv", stringsAsFactors = FALSE)
str(sms_raw)
sms_raw$type = factor(sms_raw$type)
table(sms_raw$type)
install.packages("tm")
library(tm)
?corpus
?Corpus()
sms_corpus = Corpus(VectorSource(sms_raw$text))
head(sms_raw)
type(sms_raw$text)
class(sms_raw$text)
?VectorSource()
print(sms_corpus)
corpus_clean <- tm_map(sms_corpus, tolower)
inspect(sms_corpus[1:3])
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
?tm_map
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
stopwords()
removeWords
?removeWords
?tm_map()
corpus_clean = tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
corpus_clean <- tm_map(corpus_clean, stripWhitespace)
sms_dtm <- DocumentTermMatrix(corpus_clean)
class(sms_dtm)
dim(sms_dtm)
sms_dtm[1:10,1:5]
sms_raw_train = sms_raw[1:4169,]
sms_raw_test = sms_raw[4170:5559,]
# dtm data
sms_dtm_train = sms_dtm[1:4169, ]
sms_dtm_test  = sms_dtm[4170:5559, ]
sms_corpus_train = corpus_clean[1:4169]
sms_corpus_test  = corpus_clean[4170:5559]
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
install.packages("wordcloud")
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
spam <- subset(sms_raw_train, type == "spam")
ham <- subset(sms_raw_train, type == "ham")
spam = subset(sms_raw_train, type == "spam")
ham = subset(sms_raw_train, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
head(sms_dtm_train)
findFreqTerms(sms_dtm_train, 5)
sms_dict <- Dictionary(findFreqTerms(sms_dtm_train, 5))
?Dictionary()
?removePunctuation()
sms_dict <- Dictionary(findFreqTerms(sms_dtm_train, 5))
sms_dict = Dictionary(findFreqTerms(sms_dtm_train, 5))
?DocumentTermMatrix()
sms_dict = findFreqTerms(sms_dtm_train, 5)
class(sms_dict)
type(sms_dict)
mode(sms_dict)
sms_dict[1]
sms_dict[0]
sms_dict[[1]]
head(sms_dict)
print(vignette("tm"))
?gmodels
??gmodels
?inspect()
?tm_map
tolower(JANANEE)
tolower("JANANEE")
?removeWords()
?removeNumbers()
?tolower()
?stopwords()
stopwords()
?removePunctuation
?stripWhitespace
?DocumentTermMatrix
?table()
table(sms_corpus_train)
table(sms_corpus_train$type)
head(sms_corpus_tran)
ncol(sms_corpus_train)
table(sms_raw$type)
table(sms_raw_train$type)
dim(sms_dtm_train)
dim(corpus_clean)
corpus_clean[1,]
corpus_clean[1]
corpus_clean[1:2]
corpus_clean[[1]]
ncol(sms_raw_train)
?table()
?wordcloud()
length(sms_corpus_train)
0.1*4169
10% * 4169
class(sms_raw_train)
?subset()
?subset
?findFreqTerms()
findFreqTerms(sms_dtm_train)
sms_train = DocumentTermMatrix(sms_corpus_train, list(dictionary = sms_dict))
sms_test  = DocumentTermMatrix(sms_corpus_test, list(dictionary = sms_dict))
convert_counts <- function(x)
{
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c(""No"", ""Yes""))
return(x)
￼}
convert_counts = function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c(""No"", ""Yes""))
return(x)
￼}
convert_counts = function(x) {
x <- ifelse(x > 0, 1, 0)
x = factor(x, levels = c(0, 1), labels = c(""No"", ""Yes""))
?ifelse
convert_counts = function(x) {
x = ifelse(x > 0, 1, 0)
x = factor(x, levels = c(0, 1), labels = c(""No"", ""Yes""))
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c(""No"", ""Yes""))
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
sms_train <- apply(sms_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_test, MARGIN = 2, convert_counts)
install.packages("e1071")
library(e1071)
sms_classifier = naiveBayes(sms_train, sms_raw_train$type)
str(sms_classifier)
sms_test_pred <- predict(sms_classifier, sms_test)
CrossTable(sms_test_pred, sms_raw_test$type, prop.chisq = FALSE, prop.t = FALSE,dnn = c('predicted', 'actual'))
CrossTable(sms_raw_test$type, sms_test_pred, prop.chisq = FALSE, prop.t = FALSE,dnn = c('actual', 'predicted'))
sms_classifier2 <- naiveBayes(sms_train, sms_raw_train$type, laplace = 1)
sms_test_pred2 <- predict(sms_classifier2, sms_test)
CrossTable(sms_raw_test$type, sms_test_pred2, prop.chisq = FALSE, prop.t = FALSE,dnn = c('actual', 'predicted'))
getwd()
setwd("/Users/jananee009/Zananee/Projects/BankLoan")
setwd("/Users/jananee009/Zananee/Projects/BankLoans")
getwd()
credit = read.csv("credit.csv")
head(credit)
str(credit)
?runif()
set.seed(5)
runif(7)
runif(7)
order(runif(7))
?set.seed()
runif(6)
runif(6)
runif(4)
runif(4)
set.seed(12345)
runif(5)
runif(5)
set.seed(12345)
?order()
set.seed(12345)
credit_rand = credit[order(runif(1000)), ]
summary(credit$amount)
summary(credit_rand$amount)
credit_train = credit_rand[1:900, ]
credit_test  = credit_rand[901:1000, ]
head(credit_test)
table(credit_train$default)
credit$default = factor(credit$default)
str(credit)
credit_rand = credit[order(runif(1000)), ]
set.seed(12345)
credit_rand = credit[order(runif(1000)), ]
summary(credit$amount)
summary(credit_rand$amount)
head(credit$amount)
head(credit_rand$amount)
credit_train = credit_rand[1:900, ]
credit_test  = credit_rand[901:1000, ]
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
credit$default = factor(x, levels = c(1, 2), labels = c("No", "Yes"))
credit$default = factor(credit$default, levels = c(1, 2), labels = c("No", "Yes"))
set.seed(12345)
credit_rand = credit[order(runif(1000)), ]
summary(credit$amount)
credit_train = credit_rand[1:900, ]
credit_test  = credit_rand[901:1000, ]
prop.table(table(credit_train$default))
prop.table(table(credit_test$default))
install.packages("C50")
library(C50)
?C5.0Control
?C5.0()
ncol(credit_train)
head(credit_train)
ncol(credit_train[,1:20])
head(credit_train[,1:20])
credit_model = C5.0(credit_train[,1:20], credit_train$default)
credit_model
summary(credit_model)
head(credit_test)
credit_pred <- predict(credit_model, credit_test)
credit_pred <- predict(credit_model, credit_test)
CrossTable(credit_test$default, credit_pred, prop.chisq=FALSE, prop.c=FALSE, dnn=c('actual default','predicted default'))
credit_boost10 = C5.0(credit_train[,1:20], credit_train$default, trials=10)
credit_boost10
summary(credit_boost10)
credit_boost10
credit_model
credit_boost_pred10 = predict(credit_boost10, credit_test)
CrossTable(credit_test$default, credit_boost_pred10, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual default', 'predicted default'))
summary(credit_boost10)
table(credit_train$default)
CrossTable(credit_test$default, credit_boost_pred10, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual default', 'predicted default'))
error_cost = matrix(c(0, 1, 4, 0), nrow = 2)
credit_cost = C5.0(credit_train[,1:20], credit_train$default,costs = error_cost)
error_cost
credit_cost_pred <- predict(credit_cost, credit_test)
CrossTable(credit_test$default, credit_cost_pred, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual default', 'predicted default'))
5/32
credit[1:3,]
getwd()
setwd("/Users/jananee009/Zananee/Projects/Mushrooms")
mushrooms = read.csv("mushroom.csv",header=TRUE, stringAsFactors=TRUE)
mushrooms = read.csv("mushroom.csv",header=TRUE, stringsAsFactors=TRUE)
head(mushrooms)
mushrooms = mushroom[-1]
mushrooms = mushrooms[-1]
head(mushrooms)
str(mushrooms)
mushrooms = mushrooms[-mushrooms$veilType]
mushrooms$veil_type <- NULL
table(mushroom$type)
table(mushrooms$type)
colnames(mushrooms)
colnames(mushrooms)[1]
colnames(mushrooms)[1] = type
colnames(mushrooms)[1] = "type"
colnames(mushrooms)
table(mushrooms$type)
mushrooms$type = factor(mushrooms$type, levels = c("e", "p"), labels = c("edible", "poisonous"))
table(mushrooms$type)
install.packages("RWeka")
load(RWeka)
library(RWeka)
?Rweka
??RWeka
mushroom_1R = oneR(type~.,data=mushrooms)
mushroom_1R = OneR(type~.,data=mushrooms)
mushroom_1R
summary(mushroom_1R)
mushroom_JRip = JRip(type~., data=mushrooms)
mushroom_JRip
summary(mushroom_JRip)
getwd()
setwd("/Users/jananee009/Zananee/Projects/Challenger")
launch = read.csv("challenger.csv")
b = cov(launch$temperature, launch_distress_ct)
b = cov(launch$temperature, launch$distress_ct)/var(launch$temperature)
b
a = mean(launch$distress_ct) - b*mean(launch$temperature)
a
r = cov(launch$temperature, launch$distress_ct) / (sd(launch$temperature)*sd(launch$distress_ct))
r
?cor
reg = function(y,x) {}
reg = function(y,x){
x = as.matrix(x)
x = cbind(Intercept=1, x)
solve(t(x) %*% x) %*% t(x) %*% y
}
str(launch)
result = reg(y=launch$distress_ct,x=launch[3] )
result
head(launch)
launch[3:5]
reg(y=launch$distress_ct,x=launch[3:5])
getwd()
setwd("/Users/jananee009/Zananee/Projects/Medical_Insurance")
insurance = read.csv("insurance.csv",stringsAsFactors=TRUE)
str(insurance)
summary(insurance)
summary(insurance$charges)
mean(insurance$charges)
insurance$charges[>13270]
insurance$charges[nsurance$charges>13270]
insurance$charges[insurance$charges>13270]
nrow(insurance$charges[insurance$charges>13270])
length(insurance$charges[insurance$charges>13270])
hist(insurance$charges)
table(hist(insurance$region))
table(insurance$region)
ncol(insurance)
cols(insurance)
colnames(insurance)
cor(insurance[c("age","bmi","children","charges")])
?colnames()
install.packages("psych")
pairs(insurance[c("age", "bmi", "children", "charges")])
pairs(insurance[c("age", "bmi", "children", "charges")])
??psych
library(psych)
pairs.panels(insurance[c("age", "bmi", "children", "charges")])
pairs.panels(insurance[c("age", "bmi", "children", "charges")])
ins_model = lm(charges ~ ., data = insurance)
ins_model
ins_model
summary(ins_model)
insurance$bmi30 = ifelse(insurance$bmi >= 30,1,0)
insurance$age2 <- insurance$age^2
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
insurance$bmi30 <- ifelse(insurance$bmi >= 30, 1, 0)
charges ~ bmi30*smoker
ins_model2 = ln(charges ~ age+age2+children+bmi+sex+bmi30*smoker+region, data=insurance)
ins_model2 = lm(charges ~ age+age2+children+bmi+sex+bmi30*smoker+region, data=insurance)
ins_model2
summary(ins_model2)
summary(ins_model)
